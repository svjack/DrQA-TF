{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"../data/embeddings/glove.840B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dumps_dir = \"../notebook_dumps\"\n",
    "\n",
    "def load_file(file_format, file_name):\n",
    "    assert file_format in [\"json\", \"pkl\"]\n",
    "    file_path = os.path.join(notebook_dumps_dir, \"{}.{}\".format(file_name, file_format))\n",
    "    if file_format == \"json\":\n",
    "        with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "    elif file_format == \"pkl\":\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            obj = pkl.load(f)\n",
    "    else:\n",
    "        1 / 0\n",
    "    print(\"file load from {}\".format(file_path))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file load from ../notebook_dumps/word_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "word_dict = load_file(\"pkl\", \"word_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = list(map(lambda x: word_dict[x], list(word_dict.tokens())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_keys(file_path):\n",
    "    word_index_dict = dict()\n",
    "    with open(file_path, \"r\") as f:\n",
    "        num = 0\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            word = line[:line.find(\" \")]\n",
    "            word_index_dict[word] = num\n",
    "            num += 1\n",
    "            if (num + 1) % 10000 == 0:\n",
    "                print(\"word index gen {} end\".format(num))\n",
    "    return word_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word index gen 9999 end\n",
      "word index gen 19999 end\n",
      "word index gen 29999 end\n",
      "word index gen 39999 end\n",
      "word index gen 49999 end\n",
      "word index gen 59999 end\n",
      "word index gen 69999 end\n",
      "word index gen 79999 end\n",
      "word index gen 89999 end\n",
      "word index gen 99999 end\n",
      "word index gen 109999 end\n",
      "word index gen 119999 end\n",
      "word index gen 129999 end\n",
      "word index gen 139999 end\n",
      "word index gen 149999 end\n",
      "word index gen 159999 end\n",
      "word index gen 169999 end\n",
      "word index gen 179999 end\n",
      "word index gen 189999 end\n",
      "word index gen 199999 end\n",
      "word index gen 209999 end\n",
      "word index gen 219999 end\n",
      "word index gen 229999 end\n",
      "word index gen 239999 end\n",
      "word index gen 249999 end\n",
      "word index gen 259999 end\n",
      "word index gen 269999 end\n",
      "word index gen 279999 end\n",
      "word index gen 289999 end\n",
      "word index gen 299999 end\n",
      "word index gen 309999 end\n",
      "word index gen 319999 end\n",
      "word index gen 329999 end\n",
      "word index gen 339999 end\n",
      "word index gen 349999 end\n",
      "word index gen 359999 end\n",
      "word index gen 369999 end\n",
      "word index gen 379999 end\n",
      "word index gen 389999 end\n",
      "word index gen 399999 end\n",
      "word index gen 409999 end\n",
      "word index gen 419999 end\n",
      "word index gen 429999 end\n",
      "word index gen 439999 end\n",
      "word index gen 449999 end\n",
      "word index gen 459999 end\n",
      "word index gen 469999 end\n",
      "word index gen 479999 end\n",
      "word index gen 489999 end\n",
      "word index gen 499999 end\n",
      "word index gen 509999 end\n",
      "word index gen 519999 end\n",
      "word index gen 529999 end\n",
      "word index gen 539999 end\n",
      "word index gen 549999 end\n",
      "word index gen 559999 end\n",
      "word index gen 569999 end\n",
      "word index gen 579999 end\n",
      "word index gen 589999 end\n",
      "word index gen 599999 end\n",
      "word index gen 609999 end\n",
      "word index gen 619999 end\n",
      "word index gen 629999 end\n",
      "word index gen 639999 end\n",
      "word index gen 649999 end\n",
      "word index gen 659999 end\n",
      "word index gen 669999 end\n",
      "word index gen 679999 end\n",
      "word index gen 689999 end\n",
      "word index gen 699999 end\n",
      "word index gen 709999 end\n",
      "word index gen 719999 end\n",
      "word index gen 729999 end\n",
      "word index gen 739999 end\n",
      "word index gen 749999 end\n",
      "word index gen 759999 end\n",
      "word index gen 769999 end\n",
      "word index gen 779999 end\n",
      "word index gen 789999 end\n",
      "word index gen 799999 end\n",
      "word index gen 809999 end\n",
      "word index gen 819999 end\n",
      "word index gen 829999 end\n",
      "word index gen 839999 end\n",
      "word index gen 849999 end\n",
      "word index gen 859999 end\n",
      "word index gen 869999 end\n",
      "word index gen 879999 end\n",
      "word index gen 889999 end\n",
      "word index gen 899999 end\n",
      "word index gen 909999 end\n",
      "word index gen 919999 end\n",
      "word index gen 929999 end\n",
      "word index gen 939999 end\n",
      "word index gen 949999 end\n",
      "word index gen 959999 end\n",
      "word index gen 969999 end\n",
      "word index gen 979999 end\n",
      "word index gen 989999 end\n",
      "word index gen 999999 end\n",
      "word index gen 1009999 end\n",
      "word index gen 1019999 end\n",
      "word index gen 1029999 end\n",
      "word index gen 1039999 end\n",
      "word index gen 1049999 end\n",
      "word index gen 1059999 end\n",
      "word index gen 1069999 end\n",
      "word index gen 1079999 end\n",
      "word index gen 1089999 end\n",
      "word index gen 1099999 end\n",
      "word index gen 1109999 end\n",
      "word index gen 1119999 end\n",
      "word index gen 1129999 end\n",
      "word index gen 1139999 end\n",
      "word index gen 1149999 end\n",
      "word index gen 1159999 end\n",
      "word index gen 1169999 end\n",
      "word index gen 1179999 end\n",
      "word index gen 1189999 end\n",
      "word index gen 1199999 end\n",
      "word index gen 1209999 end\n",
      "word index gen 1219999 end\n",
      "word index gen 1229999 end\n",
      "word index gen 1239999 end\n",
      "word index gen 1249999 end\n",
      "word index gen 1259999 end\n",
      "word index gen 1269999 end\n",
      "word index gen 1279999 end\n",
      "word index gen 1289999 end\n",
      "word index gen 1299999 end\n",
      "word index gen 1309999 end\n",
      "word index gen 1319999 end\n",
      "word index gen 1329999 end\n",
      "word index gen 1339999 end\n",
      "word index gen 1349999 end\n",
      "word index gen 1359999 end\n",
      "word index gen 1369999 end\n",
      "word index gen 1379999 end\n",
      "word index gen 1389999 end\n",
      "word index gen 1399999 end\n",
      "word index gen 1409999 end\n",
      "word index gen 1419999 end\n",
      "word index gen 1429999 end\n",
      "word index gen 1439999 end\n",
      "word index gen 1449999 end\n",
      "word index gen 1459999 end\n",
      "word index gen 1469999 end\n",
      "word index gen 1479999 end\n",
      "word index gen 1489999 end\n",
      "word index gen 1499999 end\n",
      "word index gen 1509999 end\n",
      "word index gen 1519999 end\n",
      "word index gen 1529999 end\n",
      "word index gen 1539999 end\n",
      "word index gen 1549999 end\n",
      "word index gen 1559999 end\n",
      "word index gen 1569999 end\n",
      "word index gen 1579999 end\n",
      "word index gen 1589999 end\n",
      "word index gen 1599999 end\n",
      "word index gen 1609999 end\n",
      "word index gen 1619999 end\n",
      "word index gen 1629999 end\n",
      "word index gen 1639999 end\n",
      "word index gen 1649999 end\n",
      "word index gen 1659999 end\n",
      "word index gen 1669999 end\n",
      "word index gen 1679999 end\n",
      "word index gen 1689999 end\n",
      "word index gen 1699999 end\n",
      "word index gen 1709999 end\n",
      "word index gen 1719999 end\n",
      "word index gen 1729999 end\n",
      "word index gen 1739999 end\n",
      "word index gen 1749999 end\n",
      "word index gen 1759999 end\n",
      "word index gen 1769999 end\n",
      "word index gen 1779999 end\n",
      "word index gen 1789999 end\n",
      "word index gen 1799999 end\n",
      "word index gen 1809999 end\n",
      "word index gen 1819999 end\n",
      "word index gen 1829999 end\n",
      "word index gen 1839999 end\n",
      "word index gen 1849999 end\n",
      "word index gen 1859999 end\n",
      "word index gen 1869999 end\n",
      "word index gen 1879999 end\n",
      "word index gen 1889999 end\n",
      "word index gen 1899999 end\n",
      "word index gen 1909999 end\n",
      "word index gen 1919999 end\n",
      "word index gen 1929999 end\n",
      "word index gen 1939999 end\n",
      "word index gen 1949999 end\n",
      "word index gen 1959999 end\n",
      "word index gen 1969999 end\n",
      "word index gen 1979999 end\n",
      "word index gen 1989999 end\n",
      "word index gen 1999999 end\n",
      "word index gen 2009999 end\n",
      "word index gen 2019999 end\n",
      "word index gen 2029999 end\n",
      "word index gen 2039999 end\n",
      "word index gen 2049999 end\n",
      "word index gen 2059999 end\n",
      "word index gen 2069999 end\n",
      "word index gen 2079999 end\n",
      "word index gen 2089999 end\n",
      "word index gen 2099999 end\n",
      "word index gen 2109999 end\n",
      "word index gen 2119999 end\n",
      "word index gen 2129999 end\n",
      "word index gen 2139999 end\n",
      "word index gen 2149999 end\n",
      "word index gen 2159999 end\n",
      "word index gen 2169999 end\n",
      "word index gen 2179999 end\n",
      "word index gen 2189999 end\n"
     ]
    }
   ],
   "source": [
    "word_index_dict = retrieve_all_keys(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_keys_set = set(map(lambda x: x.lower() ,word_index_dict.keys()))\n",
    "upper_keys_set = set(map(lambda x: x.upper() ,word_index_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(word_dict.tokens())\n",
    "lower_inter = lower_keys_set.intersection(set(tokens))\n",
    "upper_inter = upper_keys_set.intersection(set(tokens))\n",
    "all_inter = lower_inter.union(upper_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_dict_filtered = dict(map(lambda x: (x ,word_index_dict.get(x, -1)), all_inter))\n",
    "word_index_dict_filtered = dict(filter(lambda t2: t2[-1] != -1, word_index_dict_filtered.items())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_lines(input_file_path, output_file_path, word_index_dict_filtered, max_have_num = np.inf):\n",
    "    if os.path.exists(output_file_path):\n",
    "        os.remove(output_file_path)\n",
    "    f = open(output_file_path, \"w\", encoding = \"utf-8\")\n",
    "    with open(input_file_path, \"r\") as g:\n",
    "        have_num = 0\n",
    "        num = 0\n",
    "        while True:\n",
    "            line = g.readline()\n",
    "            if num not in word_index_dict_filtered.values():\n",
    "                num += 1\n",
    "                if (num + 1) % 10000 == 0:\n",
    "                    print(\"word index gen {} end\".format(num))\n",
    "                continue\n",
    "            if not line or num > max(word_index_dict_filtered.values()) or have_num > max_have_num:\n",
    "                break\n",
    "            '''\n",
    "            word = line[:line.find(\" \")]\n",
    "            if word.lower() in tokens or word.upper() in tokens:\n",
    "                f.write(\"{}\\n\".format(line.strip()))\n",
    "            '''\n",
    "            f.write(\"{}\\n\".format(line.strip()))\n",
    "            have_num += 1\n",
    "            num += 1\n",
    "            if (have_num + 1) % 100 == 0:\n",
    "                print(\"word find gen {} end\".format(have_num))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_lines(embedding_path, \"glove_filtered.txt\", word_index_dict_filtered, 45000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"glove_filtered.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    glove_embedding_dict = dict()\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        word = line[:line.find(\" \")]\n",
    "        float_text = line[line.find(\" \") + 1:]\n",
    "        floats = np.asarray(list(map(float, float_text.split(\" \"))), dtype = np.float32)\n",
    "        glove_embedding_dict[word] = floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_dict(word_dict, glove_embedding_dict, with_random = True):\n",
    "    np.random.seed(0)\n",
    "    #req = np.random.random(size = [len(word_dict), 300])\n",
    "    req = np.zeros([len(word_dict), 300])\n",
    "    tokens = word_dict.tokens()\n",
    "    for token in tokens:\n",
    "        if token in glove_embedding_dict:\n",
    "            req[word_dict[token]] = glove_embedding_dict[token]\n",
    "        else:\n",
    "            if with_random:\n",
    "                req[word_dict[token]] = np.random.random((300,))\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_require = generate_embedding_dict(word_dict, glove_embedding_dict, with_random = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"glove_embedding.pkl\"\n",
    "assert not os.path.exists(embedding_path)\n",
    "import pickle as pkl\n",
    "with open(embedding_path, \"wb\") as f:\n",
    "    pkl.dump(glove_embedding_require, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
